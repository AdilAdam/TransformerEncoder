![Transformer-encoder](https://github.com/AdilAdam/TransformerEncoder/assets/126153483/120b0585-20ee-4273-b714-b9d909546b6c)

<div align="center">

**PyTorch implementation of Transformer encoder: Transformer encoder for Classification Tasks.**
                          
**just for learning or research purpose**

  
</div>

***
  
Transformer model is a neural network that learns context and thus meaning by tracking relationships in sequential data like the words in this sentence, which means Transformer models are good at capturing content-based global interactions.Transformer models apply an evolving set of mathematical techniques, called attention or self-attention, to detect subtle ways even distant data elements in a series influence and depend on each other.

![transformer](https://github.com/AdilAdam/TransformerEncoder/assets/126153483/d9385695-81e8-4cec-98bd-d0939744e049)


In this repository just transformer encoder was implemented, for more detail further check the paper [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)

## TODO
- Transformer encoder 
- Implemented on Pytorch (version=1.11.0)
